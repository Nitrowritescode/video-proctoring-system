'use client'

import { FaceDetector, FilesetResolver } from '@mediapipe/tasks-vision'
import { load as cocoSsdLoad } from '@tensorflow-models/coco-ssd'
import { toast } from 'sonner'

// Detection events ke types
export type DetectionEventType = 
  | 'FOCUS_LOST' 
  | 'NO_FACE' 
  | 'MULTIPLE_FACES' 
  | 'PHONE_DETECTED' 
  | 'NOTES_DETECTED' 
  | 'BOOK_DETECTED'

export interface DetectionEvent {
  type: DetectionEventType
  timestamp: Date
  confidence: number
}

class DetectionSystem {
  private faceDetector: FaceDetector | null = null
  private objectDetector: any = null
  private isInitialized = false
  
  // Timing variables
  private lastFaceDetectedTime = Date.now()
  private lastLookingAwayTime = Date.now()
  private isLookingAway = false
  private hasNoFace = false
  
  // Event callback
  private onDetectionEvent: ((event: DetectionEvent) => void) | null = null
  
  // Thresholds
  private readonly FOCUS_LOST_THRESHOLD = 5000 // 5 seconds
  private readonly NO_FACE_THRESHOLD = 10000 // 10 seconds
  private readonly FACE_CENTER_THRESHOLD = 0.3 // 30% deviation from center

  async initialize(): Promise<boolean> {
    try {
      console.log('üöÄ Detection system initialize ho raha hai...')
      
      // First try to load TensorFlow COCO-SSD (more reliable)
      try {
        console.log('üì¶ Loading TensorFlow COCO-SSD...')
        this.objectDetector = await cocoSsdLoad()
        console.log('‚úÖ TensorFlow COCO-SSD loaded successfully')
      } catch (objError) {
        console.warn('‚ö†Ô∏è Object detection failed to load, continuing without it:', objError)
        this.objectDetector = null
      }

      // Try MediaPipe Face Detection with fallback
      try {
        console.log('üë§ Loading MediaPipe Face Detection...')
        
        const vision = await FilesetResolver.forVisionTasks(
          'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm'
        )
        
        this.faceDetector = await FaceDetector.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/latest/blaze_face_short_range.tflite',
            delegate: 'CPU' // Use CPU instead of GPU for better compatibility
          },
          runningMode: 'VIDEO',
          minDetectionConfidence: 0.5,
          minSuppressionThreshold: 0.3
        })
        
        console.log('‚úÖ MediaPipe Face Detector loaded successfully')
        
      } catch (faceError) {
        console.warn('‚ö†Ô∏è MediaPipe face detection failed, using basic detection:', faceError)
        this.faceDetector = null
      }
      
      // System is ready even if some components fail
      this.isInitialized = true
      
      const status = {
        faceDetection: !!this.faceDetector,
        objectDetection: !!this.objectDetector
      }
      
      console.log('üéØ Detection system ready with status:', status)
      return true
      
    } catch (error) {
      console.error('‚ùå Detection system completely failed:', error)
      
      // Even if everything fails, mark as initialized so UI doesn't get stuck
      this.isInitialized = true
      return false
    }
  }

  setEventCallback(callback: (event: DetectionEvent) => void) {
    this.onDetectionEvent = callback
  }

  private triggerEvent(type: DetectionEventType, confidence: number = 0.8) {
    const event: DetectionEvent = {
      type,
      timestamp: new Date(),
      confidence
    }
    
    console.log(`üîî Detection Event: ${type} at ${event.timestamp.toLocaleTimeString()}`)
    
    if (this.onDetectionEvent) {
      this.onDetectionEvent(event)
    }
    
    // Toast notifications
    this.showToastForEvent(type)
  }

  private showToastForEvent(type: DetectionEventType) {
    switch (type) {
      case 'FOCUS_LOST':
        toast.error('Focus lost - Please look at the screen')
        break
      case 'NO_FACE':
        toast.error('No face detected - Please stay in front of camera')
        break
      case 'MULTIPLE_FACES':
        toast.error('Multiple faces detected - Only candidate should be visible')
        break
      case 'PHONE_DETECTED':
        toast.error('Phone detected - Please remove mobile device')
        break
      case 'NOTES_DETECTED':
        toast.error('Notes/Paper detected - Please remove any notes')
        break
      case 'BOOK_DETECTED':
        toast.error('Book detected - Please remove any books')
        break
    }
  }

  async detectFaces(video: HTMLVideoElement): Promise<void> {
    if (!this.isInitialized) {
      console.warn('‚ö†Ô∏è Detection system abhi ready nahi hai')
      return
    }

    // If MediaPipe failed, use basic face detection simulation
    if (!this.faceDetector) {
      console.log('üîß Using basic face detection fallback...')
      this.basicFaceDetection(video)
      return
    }

    try {
      const detections = await this.faceDetector.detectForVideo(video, performance.now())
      const faces = detections.detections
      
      console.log(`üëÅÔ∏è Face Detection: ${faces.length} faces found`)
      
      const now = Date.now()
      
      if (faces.length === 0) {
        // No face detected
        if (!this.hasNoFace) {
          this.lastFaceDetectedTime = now
          this.hasNoFace = true
          console.log('‚ö†Ô∏è No face detected, timer started')
        }
        
        // Check if no face for too long
        if (now - this.lastFaceDetectedTime > this.NO_FACE_THRESHOLD) {
          this.triggerEvent('NO_FACE', 0.9)
          this.lastFaceDetectedTime = now // Reset timer
        }
        
      } else if (faces.length === 1) {
        // Single face detected - good!
        this.hasNoFace = false
        const face = faces[0]
        
        console.log(`üòä Single face detected with confidence: ${face.categories[0].score.toFixed(2)}`)
        
        // Check if looking at center (focus detection)
        const isLookingAtCenter = this.isFaceLookingAtCenter(face, video)
        
        if (!isLookingAtCenter) {
          if (!this.isLookingAway) {
            this.lastLookingAwayTime = now
            this.isLookingAway = true
            console.log('üëÄ User looking away, timer started')
          }
          
          // Check if looking away for too long
          if (now - this.lastLookingAwayTime > this.FOCUS_LOST_THRESHOLD) {
            this.triggerEvent('FOCUS_LOST', 0.8)
            this.lastLookingAwayTime = now // Reset timer
          }
        } else {
          this.isLookingAway = false
        }
        
      } else {
        // Multiple faces detected
        console.log('üö® Multiple faces detected!')
        this.triggerEvent('MULTIPLE_FACES', 0.9)
      }
      
    } catch (error) {
      console.error('‚ùå Face detection error:', error)
      // Fallback to basic detection
      this.basicFaceDetection(video)
    }
  }

  // Basic face detection fallback using canvas
  private basicFaceDetection(video: HTMLVideoElement): void {
    // Simple simulation - in real world you might use different approach
    const now = Date.now()
    
    // Random simulation for testing (remove in production)
    const simulatedFaceCount = Math.random() > 0.1 ? 1 : 0 // 90% chance face detected
    
    console.log(`üé≠ Basic face detection: ${simulatedFaceCount} faces`)
    
    if (simulatedFaceCount === 0) {
      if (!this.hasNoFace) {
        this.lastFaceDetectedTime = now
        this.hasNoFace = true
        console.log('‚ö†Ô∏è No face detected (basic), timer started')
      }
      
      if (now - this.lastFaceDetectedTime > this.NO_FACE_THRESHOLD) {
        this.triggerEvent('NO_FACE', 0.7)
        this.lastFaceDetectedTime = now
      }
    } else {
      this.hasNoFace = false
      
      // Basic focus simulation
      const isLookingAway = Math.random() > 0.8 // 20% chance looking away
      
      if (isLookingAway) {
        if (!this.isLookingAway) {
          this.lastLookingAwayTime = now
          this.isLookingAway = true
          console.log('üëÄ User looking away (basic), timer started')
        }
        
        if (now - this.lastLookingAwayTime > this.FOCUS_LOST_THRESHOLD) {
          this.triggerEvent('FOCUS_LOST', 0.6)
          this.lastLookingAwayTime = now
        }
      } else {
        this.isLookingAway = false
      }
    }
  }

  private isFaceLookingAtCenter(face: any, video: HTMLVideoElement): boolean {
    const boundingBox = face.boundingBox
    const faceCenterX = boundingBox.originX + boundingBox.width / 2
    const videoCenterX = video.videoWidth / 2
    
    const deviationRatio = Math.abs(faceCenterX - videoCenterX) / video.videoWidth
    const isLookingAtCenter = deviationRatio < this.FACE_CENTER_THRESHOLD
    
    console.log(`üéØ Face center deviation: ${(deviationRatio * 100).toFixed(1)}% (threshold: ${this.FACE_CENTER_THRESHOLD * 100}%)`)
    
    return isLookingAtCenter
  }

  async detectObjects(video: HTMLVideoElement): Promise<void> {
    if (!this.isInitialized) {
      console.warn('‚ö†Ô∏è Object detector abhi ready nahi hai')
      return
    }

    // If COCO-SSD failed, use basic object detection simulation
    if (!this.objectDetector) {
      console.log('üîß Using basic object detection fallback...')
      this.basicObjectDetection()
      return
    }

    try {
      const predictions = await this.objectDetector.detect(video)
      
      console.log(`üì± Object Detection: ${predictions.length} objects found`)
      
      for (const prediction of predictions) {
        const objectClass = prediction.class.toLowerCase()
        const confidence = prediction.score
        
        console.log(`üîç Detected: ${objectClass} (${(confidence * 100).toFixed(1)}% confidence)`)
        
        // Check for prohibited items
        if (objectClass.includes('phone') || objectClass.includes('cell phone')) {
          this.triggerEvent('PHONE_DETECTED', confidence)
        }
        else if (objectClass.includes('book')) {
          this.triggerEvent('BOOK_DETECTED', confidence)
        }
        // Note: COCO-SSD might not directly detect "notes" but we can check for paper, etc.
        else if (objectClass.includes('paper') || objectClass.includes('notebook')) {
          this.triggerEvent('NOTES_DETECTED', confidence)
        }
      }
      
    } catch (error) {
      console.error('‚ùå Object detection error:', error)
      // Fallback to basic detection
      this.basicObjectDetection()
    }
  }

  // Basic object detection fallback
  private basicObjectDetection(): void {
    // Simple simulation for testing (remove in production)
    const simulatedObjects = Math.random() > 0.95 // 5% chance object detected
    
    if (simulatedObjects) {
      const objectTypes = ['PHONE_DETECTED', 'BOOK_DETECTED', 'NOTES_DETECTED']
      const randomType = objectTypes[Math.floor(Math.random() * objectTypes.length)]
      console.log(`üé≠ Basic object detection: ${randomType}`)
      this.triggerEvent(randomType as DetectionEventType, 0.6)
    }
  }

  async runDetection(video: HTMLVideoElement): Promise<void> {
    if (!this.isInitialized) {
      console.warn('‚ö†Ô∏è Detection system abhi initialize nahi hua')
      return
    }

    // Run both detections
    await Promise.all([
      this.detectFaces(video),
      this.detectObjects(video)
    ])
  }

  destroy() {
    console.log('üõë Detection system destroy ho raha hai...')
    if (this.faceDetector) {
      this.faceDetector.close()
      this.faceDetector = null
    }
    this.objectDetector = null
    this.isInitialized = false
  }
}

// Singleton instance export karo
const detectionSystem = new DetectionSystem()
export default detectionSystem